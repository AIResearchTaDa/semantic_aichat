"""
–ú–æ–¥—É–ª—å –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —á–∞—Ç-–ø–æ—à—É–∫—É —Ç–æ–≤–∞—Ä—ñ–≤.
–ó–±–µ—Ä—ñ–≥–∞—î –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ score —Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —è–∫–æ—Å—Ç—ñ –ø—ñ–¥–±–æ—Ä—É.
"""

import os
import json
import datetime
from typing import List, Dict, Any, Optional
from pathlib import Path


class SearchLogger:
    """
    –õ–æ–≥–µ—Ä –¥–ª—è –∑–∞–ø–∏—Å—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏.
    –û—Ä–≥–∞–Ω—ñ–∑–æ–≤—É—î –ª–æ–≥–∏ –ø–æ —Å–µ—Å—ñ—è—Ö –¥–ª—è –∑—Ä—É—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É.
    """
    
    def __init__(self, logs_dir: str = "search_logs"):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥–µ—Ä–∞.
        
        Args:
            logs_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ª–æ–≥—ñ–≤
        """
        self.logs_dir = Path(logs_dir)
        self.logs_dir.mkdir(exist_ok=True)
        self.log_file = self.logs_dir / "search_queries.json"
        self.readable_file = self.logs_dir / "search_queries_readable.txt"
        
    def _load_logs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ —ñ—Å–Ω—É—é—á—ñ –ª–æ–≥–∏ –∑ —Ñ–∞–π–ª—É."""
        if not self.log_file.exists():
            return []
        
        try:
            with open(self.log_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, Exception):
            return []
    
    def _save_logs(self, logs: List[Dict[str, Any]]):
        """–ó–±–µ—Ä—ñ–≥–∞—î –ª–æ–≥–∏ —É —Ñ–∞–π–ª –∑ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è–º."""
        with open(self.log_file, "w", encoding="utf-8") as f:
            json.dump(logs, f, ensure_ascii=False, indent=2)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ readable –≤–µ—Ä—Å—ñ—é –∑ —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞–º–∏ –º—ñ–∂ —Å–µ—Å—ñ—è–º–∏
        self._create_readable_file(logs)
    
    def _create_readable_file(self, logs: List[Dict[str, Any]]):
        """–°—Ç–≤–æ—Ä—é—î —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª –∑ –≥–∞—Ä–Ω–∏–º —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è–º —Ç–∞ —Ä–æ–∑–¥—ñ–ª—å–Ω–∏–∫–∞–º–∏ –º—ñ–∂ —Å–µ—Å—ñ—è–º–∏."""
        if not logs:
            return
        
        # –ì—Ä—É–ø—É—î–º–æ –ª–æ–≥–∏ –ø–æ —Å–µ—Å—ñ—è—Ö
        sessions = {}
        for log in logs:
            session_id = log.get("session_id", "unknown")
            if session_id not in sessions:
                sessions[session_id] = []
            sessions[session_id].append(log)
        
        with open(self.readable_file, "w", encoding="utf-8") as f:
            f.write("=" * 100 + "\n")
            f.write(f"{'–õ–û–ì–ò –ü–û–®–£–ö–û–í–ò–• –ó–ê–ü–ò–¢–Ü–í':^100}\n")
            f.write(f"{'–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: ' + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'):^100}\n")
            f.write("=" * 100 + "\n\n")
            
            for session_idx, (session_id, session_logs) in enumerate(sorted(sessions.items()), 1):
                if session_idx > 1:
                    f.write("\n" + "-" * 100 + "\n")
                    f.write(f"{'–ù–û–í–ê –°–ï–°–Ü–Ø':^100}\n")
                    f.write("-" * 100 + "\n\n")
                
                f.write(f"üì± –°–ï–°–Ü–Ø: {session_id}\n")
                f.write(f"üìä –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—ñ–≤ –≤ —Å–µ—Å—ñ—ó: {len(session_logs)}\n")
                f.write(f"üïê –ü–µ—Ä—à–∏–π –∑–∞–ø–∏—Ç: {session_logs[0]['timestamp']}\n")
                f.write(f"üïê –û—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞–ø–∏—Ç: {session_logs[-1]['timestamp']}\n")
                f.write("\n")
                
                for query_idx, log in enumerate(session_logs, 1):
                    f.write(f"  {'‚îÄ' * 96}\n")
                    f.write(f"  –ó–∞–ø–∏—Ç #{query_idx}\n")
                    f.write(f"  {'‚îÄ' * 96}\n")
                    f.write(f"  üïê –ß–∞—Å:        {log['timestamp']}\n")
                    f.write(f"  üîç –ó–∞–ø–∏—Ç:      {log['query']}\n")
                    f.write(f"  üéØ –¢–∏–ø:        {log['intent']}\n")
                    
                    stats = log['search_stats']
                    f.write(f"\n  üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
                    f.write(f"     ‚Ä¢ –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä—ñ–≤:    {stats['total_found']}\n")
                    f.write(f"     ‚Ä¢ –ü—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó:    {stats['after_filtering']} ({stats['filtering_rate']*100:.1f}%)\n")
                    f.write(f"     ‚Ä¢ Max score:           {stats['max_score']}\n")
                    f.write(f"     ‚Ä¢ –ü–æ—Ä—ñ–≥ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó:    {stats['threshold_final']}\n")
                    f.write(f"     ‚Ä¢ –ß–∞—Å –ø–æ—à—É–∫—É:          {stats['search_time_ms']:.0f} –º—Å\n")
                    
                    if log.get('subqueries'):
                        f.write(f"\n  üîé –ü–Ü–î–ó–ê–ü–ò–¢–ò ({len(log['subqueries'])}):\n")
                        for i, subq in enumerate(log['subqueries'][:5], 1):
                            f.write(f"     {i}. {subq}\n")
                    
                    if log.get('top_products'):
                        f.write(f"\n  üèÜ –¢–û–ü-10 –¢–û–í–ê–†–Ü–í:\n")
                        for i, prod in enumerate(log['top_products'][:10], 1):
                            recommended = "‚≠ê" if prod.get('recommended') else "  "
                            f.write(f"     {recommended} {i:2d}. [{prod['score']:.4f}] {prod['name']}\n")
                    
                    if log.get('additional_info', {}).get('categories'):
                        cats = log['additional_info']['categories']
                        f.write(f"\n  üìÅ –ö–ê–¢–ï–ì–û–†–Ü–á ({len(cats)}): {', '.join(cats[:5])}\n")
                    
                    f.write("\n")
    
    def log_search_query(
        self,
        session_id: str,
        query: str,
        subqueries: List[str],
        total_products_found: int,
        products_after_filtering: int,
        max_score: float,
        threshold: float,
        adaptive_min: float,
        dynamic_threshold: float,
        top_products: List[Dict[str, Any]],
        search_time_ms: float,
        intent: str = "product_search",
        additional_info: Optional[Dict[str, Any]] = None
    ):
        """
        –õ–æ–≥—É—î –æ–¥–∏–Ω –∑–∞–ø–∏—Ç –ø–æ—à—É–∫—É –∑ —É—Å—ñ–º–∞ –¥–µ—Ç–∞–ª—è–º–∏.
        
        Args:
            session_id: –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —Å–µ—Å—ñ—ó
            query: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            subqueries: –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ –ø—ñ–¥–∑–∞–ø–∏—Ç–∏
            total_products_found: –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤
            products_after_filtering: –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—ñ—Å–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó
            max_score: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π score —Å–µ—Ä–µ–¥ —Ç–æ–≤–∞—Ä—ñ–≤
            threshold: –§—ñ–Ω–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó
            adaptive_min: –ê–¥–∞–ø—Ç–∏–≤–Ω–∏–π –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥
            dynamic_threshold: –î–∏–Ω–∞–º—ñ—á–Ω–∏–π –ø–æ—Ä—ñ–≥
            top_products: –¢–æ–ø —Ç–æ–≤–∞—Ä—ñ–≤ –∑ —ó—Ö scores (ID, –Ω–∞–∑–≤–∞, score)
            search_time_ms: –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –ø–æ—à—É–∫—É –≤ –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∞—Ö
            intent: –¢–∏–ø –∑–∞–ø–∏—Ç—É (product_search, clarification, invalid)
            additional_info: –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è (–∫–∞—Ç–µ–≥–æ—Ä—ñ—ó, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —Ç–æ—â–æ)
        """
        timestamp = datetime.datetime.now().isoformat()
        
        log_entry = {
            "timestamp": timestamp,
            "session_id": session_id,
            "query": query,
            "intent": intent,
            "subqueries": subqueries,
            "search_stats": {
                "total_found": total_products_found,
                "after_filtering": products_after_filtering,
                "filtering_rate": round(products_after_filtering / total_products_found, 3) if total_products_found > 0 else 0,
                "max_score": round(max_score, 4),
                "threshold_final": round(threshold, 4),
                "threshold_adaptive_min": round(adaptive_min, 4),
                "threshold_dynamic": round(dynamic_threshold, 4),
                "search_time_ms": round(search_time_ms, 2)
            },
            "top_products": top_products,
            "additional_info": additional_info or {}
        }
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —ñ—Å–Ω—É—é—á—ñ –ª–æ–≥–∏, –¥–æ–¥–∞—î–º–æ –Ω–æ–≤–∏–π —ñ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ
        logs = self._load_logs()
        logs.append(log_entry)
        self._save_logs(logs)
    
    def get_session_logs(self, session_id: str) -> List[Dict[str, Any]]:
        """
        –ß–∏—Ç–∞—î –≤—Å—ñ –ª–æ–≥–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó —Å–µ—Å—ñ—ó.
        
        Args:
            session_id: –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —Å–µ—Å—ñ—ó
            
        Returns:
            –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –∑–∞–ø–∏—Ç—ñ–≤ –≤ —Å–µ—Å—ñ—ó
        """
        all_logs = self._load_logs()
        return [log for log in all_logs if log.get("session_id") == session_id]
    
    def get_all_sessions(self) -> List[str]:
        """
        –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤ —Å–µ—Å—ñ–π.
        
        Returns:
            –°–ø–∏—Å–æ–∫ session_id
        """
        all_logs = self._load_logs()
        sessions = list(set(log.get("session_id") for log in all_logs if log.get("session_id")))
        return sorted(sessions)
    
    def generate_session_report(self, session_id: str) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç –ø–æ —Å–µ—Å—ñ—ó –∑ –∞–Ω–∞–ª—ñ—Ç–∏–∫–æ—é.
        
        Args:
            session_id: –Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä —Å–µ—Å—ñ—ó
            
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ –∞–Ω–∞–ª—ñ—Ç–∏–∫–æ—é –ø–æ —Å–µ—Å—ñ—ó
        """
        logs = self.get_session_logs(session_id)
        
        if not logs:
            return {"error": "Session not found"}
        
        total_queries = len(logs)
        avg_search_time = sum(log["search_stats"]["search_time_ms"] for log in logs) / total_queries
        avg_products_found = sum(log["search_stats"]["total_found"] for log in logs) / total_queries
        avg_products_filtered = sum(log["search_stats"]["after_filtering"] for log in logs) / total_queries
        avg_filtering_rate = sum(log["search_stats"]["filtering_rate"] for log in logs) / total_queries
        
        # –ê–Ω–∞–ª—ñ–∑ score-—ñ–≤
        all_scores = []
        for log in logs:
            all_scores.extend([p["score"] for p in log["top_products"]])
        
        avg_max_score = sum(log["search_stats"]["max_score"] for log in logs) / total_queries
        
        report = {
            "session_id": session_id,
            "total_queries": total_queries,
            "first_query_time": logs[0]["timestamp"],
            "last_query_time": logs[-1]["timestamp"],
            "average_stats": {
                "search_time_ms": round(avg_search_time, 2),
                "products_found": round(avg_products_found, 1),
                "products_after_filtering": round(avg_products_filtered, 1),
                "filtering_rate": round(avg_filtering_rate, 3),
                "max_score": round(avg_max_score, 4)
            },
            "score_distribution": {
                "min": round(min(all_scores), 4) if all_scores else 0,
                "max": round(max(all_scores), 4) if all_scores else 0,
                "avg": round(sum(all_scores) / len(all_scores), 4) if all_scores else 0
            },
            "queries": [
                {
                    "query": log["query"],
                    "timestamp": log["timestamp"],
                    "found": log["search_stats"]["total_found"],
                    "filtered": log["search_stats"]["after_filtering"],
                    "max_score": log["search_stats"]["max_score"]
                }
                for log in logs
            ]
        }
        
        return report
    
    def export_all_sessions_report(self, output_file: str = "all_sessions_report.json"):
        """
        –ï–∫—Å–ø–æ—Ä—Ç—É—î –∑–≤—ñ—Ç –ø–æ –≤—Å—ñ—Ö —Å–µ—Å—ñ—è—Ö –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª.
        
        Args:
            output_file: –Ü–º'—è —Ñ–∞–π–ª—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–≤—ñ—Ç—É
        """
        all_sessions = self.get_all_sessions()
        
        reports = []
        for session_id in all_sessions:
            report = self.generate_session_report(session_id)
            reports.append(report)
        
        output_path = self.logs_dir / output_file
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump({
                "generated_at": datetime.datetime.now().isoformat(),
                "total_sessions": len(reports),
                "sessions": reports
            }, f, ensure_ascii=False, indent=2)
        
        return str(output_path)

